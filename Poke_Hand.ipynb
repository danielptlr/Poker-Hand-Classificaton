{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ashwani Singh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing all the require library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path for the data set which is taken from UCI machine library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path='https://archive.ics.uci.edu/ml/machine-learning-databases/poker/poker-hand-training-true.data'\n",
    "test_path='https://archive.ics.uci.edu/ml/machine-learning-databases/poker/poker-hand-testing.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set the columns name for the data set\n",
    "\n",
    "col_names=['s1','c1','s2','c2','s3','c3','s4','c4','s5','c5','class' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading the data from path and assigning variables name\n",
    "\n",
    "poker_train=pd.read_table(train_path, sep=',', names=col_names)\n",
    "poker_test=pd.read_table(test_path, sep=',', names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s1</th>\n",
       "      <th>c1</th>\n",
       "      <th>s2</th>\n",
       "      <th>c2</th>\n",
       "      <th>s3</th>\n",
       "      <th>c3</th>\n",
       "      <th>s4</th>\n",
       "      <th>c4</th>\n",
       "      <th>s5</th>\n",
       "      <th>c5</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   s1  c1  s2  c2  s3  c3  s4  c4  s5  c5  class\n",
       "0   1  10   1  11   1  13   1  12   1   1      9\n",
       "1   2  11   2  13   2  10   2  12   2   1      9\n",
       "2   3  12   3  11   3  13   3  10   3   1      9\n",
       "3   4  10   4  11   4   1   4  13   4  12      9\n",
       "4   4   1   4  13   4  12   4  11   4  10      9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s1</th>\n",
       "      <th>c1</th>\n",
       "      <th>s2</th>\n",
       "      <th>c2</th>\n",
       "      <th>s3</th>\n",
       "      <th>c3</th>\n",
       "      <th>s4</th>\n",
       "      <th>c4</th>\n",
       "      <th>s5</th>\n",
       "      <th>c5</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   s1  c1  s2  c2  s3  c3  s4  c4  s5  c5  class\n",
       "0   1   1   1  13   2   4   2   3   1  12      0\n",
       "1   3  12   3   2   3  11   4   5   2   5      1\n",
       "2   1   9   4   6   1   4   3   2   3   9      1\n",
       "3   1   4   3  13   2  13   2   1   3   6      1\n",
       "4   3  10   2   7   1   2   2  11   4   9      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poker_train.head()\n",
    "poker_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=poker_train\n",
    "test=poker_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert the suit of cards variables into category\n",
    "\n",
    "col=['s1','s2','s3','s4','s5']\n",
    "for i in col:\n",
    "    train[i]=train[i].astype('category')\n",
    "    test[i]=test[i].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One hot encoding for the categorical Variable\n",
    "\n",
    "train=pd.get_dummies(train)\n",
    "test=pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>class</th>\n",
       "      <th>s1_1</th>\n",
       "      <th>s1_2</th>\n",
       "      <th>s1_3</th>\n",
       "      <th>s1_4</th>\n",
       "      <th>...</th>\n",
       "      <th>s3_3</th>\n",
       "      <th>s3_4</th>\n",
       "      <th>s4_1</th>\n",
       "      <th>s4_2</th>\n",
       "      <th>s4_3</th>\n",
       "      <th>s4_4</th>\n",
       "      <th>s5_1</th>\n",
       "      <th>s5_2</th>\n",
       "      <th>s5_3</th>\n",
       "      <th>s5_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   c1  c2  c3  c4  c5  class  s1_1  s1_2  s1_3  s1_4  ...   s3_3  s3_4  s4_1  \\\n",
       "0  10  11  13  12   1      9     1     0     0     0  ...      0     0     1   \n",
       "1  11  13  10  12   1      9     0     1     0     0  ...      0     0     0   \n",
       "2  12  11  13  10   1      9     0     0     1     0  ...      1     0     0   \n",
       "3  10  11   1  13  12      9     0     0     0     1  ...      0     1     0   \n",
       "4   1  13  12  11  10      9     0     0     0     1  ...      0     1     0   \n",
       "\n",
       "   s4_2  s4_3  s4_4  s5_1  s5_2  s5_3  s5_4  \n",
       "0     0     0     0     1     0     0     0  \n",
       "1     1     0     0     0     1     0     0  \n",
       "2     0     1     0     0     0     1     0  \n",
       "3     0     0     1     0     0     0     1  \n",
       "4     0     0     1     0     0     0     1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 26 variables out of which 'class' is the target variable. So, the total number of explantory variables will be 25 and one target variable. Target variable has total no. 10 classes so, first we have to convert it into category and then get dummy variables for class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train=np.array(train.drop('class', axis=1))\n",
    "y=pd.get_dummies(train['class'].astype('category'))\n",
    "y_train=np.array(y)\n",
    "\n",
    "x_test=np.array(test.drop('class', axis=1))\n",
    "y1=pd.get_dummies(test['class'].astype('category'))\n",
    "y_test=np.array(y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow- Neural Net\n",
    "Here I am using neural net for classification. For that I am concidering 3 hidden layers with 500 nodes at each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_nodes_hl1=500\n",
    "n_nodes_hl2=500\n",
    "n_nodes_hl3=500\n",
    "\n",
    "n_classes=10\n",
    "\n",
    "x=tf.placeholder('float',[None, 25])\n",
    "y=tf.placeholder('float',[None,n_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation function- For hidden layers i am cosidering tanh and for the output layer i am taking softmax. Here i am using Adam optimizer and with learning rate 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neural_network_model(data):\n",
    "    hidden_1_layer={'weights':tf.Variable(tf.random_normal([25, n_nodes_hl1])),\n",
    "                   'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
    "    \n",
    "    hidden_2_layer={'weights':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n",
    "                   'biases':tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
    "    \n",
    "    hidden_3_layer={'weights':tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])),\n",
    "                   'biases':tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
    "\n",
    "    output_layer={'weights':tf.Variable(tf.random_normal([n_nodes_hl3,n_classes])),\n",
    "                   'biases':tf.Variable(tf.random_normal([n_classes]))}\n",
    "\n",
    "    l1=tf.add(tf.matmul(data,hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
    "    l1=tf.nn.tanh(l1)\n",
    "    \n",
    "    l2=tf.add(tf.matmul(l1,hidden_2_layer['weights']), hidden_2_layer['biases'])\n",
    "    l2=tf.nn.tanh(l2)\n",
    "\n",
    "    l3=tf.add(tf.matmul(l1,hidden_3_layer['weights']), hidden_3_layer['biases'])\n",
    "    l3=tf.nn.tanh(l3)\n",
    "    \n",
    "    output=tf.matmul(l3,output_layer['weights'])+ output_layer['biases']\n",
    "    output=tf.nn.softmax(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Model without batch processesing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_neural_network(x):\n",
    "    prediction=neural_network_model(x)\n",
    "    cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y))\n",
    "    \n",
    "    learning_rate= 0.1\n",
    "    optimizer= tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "    hm_epochs=10\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch in range(hm_epochs):\n",
    "            epoch_loss=0\n",
    "            _,c=sess.run([optimizer, cost], feed_dict={x: x_train, y: y_train})\n",
    "            epoch_loss+=c\n",
    "            print('Epoch', epoch, 'completed out of', hm_epochs,'loss: ',epoch_loss)\n",
    "        correct=tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
    "        accuracy= tf.reduce_mean (tf.cast(correct, 'float'))\n",
    "        print('Accuracy:', accuracy.eval({x:x_test, y:y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed out of 10 loss:  2.43750786781\n",
      "Epoch 1 completed out of 10 loss:  2.01901054382\n",
      "Epoch 2 completed out of 10 loss:  1.96142196655\n",
      "Epoch 3 completed out of 10 loss:  1.96149492264\n",
      "Epoch 4 completed out of 10 loss:  1.96149492264\n",
      "Epoch 5 completed out of 10 loss:  1.96149492264\n",
      "Epoch 6 completed out of 10 loss:  1.96149492264\n",
      "Epoch 7 completed out of 10 loss:  1.96149492264\n",
      "Epoch 8 completed out of 10 loss:  1.96149492264\n",
      "Epoch 9 completed out of 10 loss:  1.96149492264\n",
      "Accuracy: 0.501209\n"
     ]
    }
   ],
   "source": [
    "train_neural_network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "The accuracy for the test data is- 50.12%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras - Tensorflow\n",
    "Importing models and layers from Keras Library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target variable has total no. 10 classes so, first we have to convert it into category and then get dummy variables for class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train=np.array(train.drop('class', axis=1))\n",
    "y=pd.get_dummies(train['class'].astype('category'))\n",
    "y_train=np.array(y)\n",
    "\n",
    "x_test=np.array(test.drop('class', axis=1))\n",
    "y1=pd.get_dummies(test['class'].astype('category'))\n",
    "y_test=np.array(y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am using 'RELU' activation function for the hidden layers and 'SOFTMAX' activation\n",
    "function for output Layers. For the optimization i used Adam Optimizer. At each hidden layer i took 500 nodes and at output 10 nodes because we have 10 classes. Here i am using 50 epoch and batch size 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25010 samples, validate on 1000000 samples\n",
      "Epoch 1/50\n",
      "25010/25010 [==============================] - 76s - loss: 0.9941 - acc: 0.5121 - val_loss: 0.9650 - val_acc: 0.5323\n",
      "Epoch 2/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.9565 - acc: 0.5408 - val_loss: 0.9491 - val_acc: 0.5469\n",
      "Epoch 3/50\n",
      "25010/25010 [==============================] - 69s - loss: 0.9480 - acc: 0.5468 - val_loss: 1.0082 - val_acc: 0.5267\n",
      "Epoch 4/50\n",
      "25010/25010 [==============================] - 70s - loss: 0.9355 - acc: 0.5587 - val_loss: 0.9427 - val_acc: 0.5540\n",
      "Epoch 5/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.9276 - acc: 0.5638 - val_loss: 0.9304 - val_acc: 0.5614\n",
      "Epoch 6/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.9152 - acc: 0.5753 - val_loss: 0.9192 - val_acc: 0.5703\n",
      "Epoch 7/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.8975 - acc: 0.5852 - val_loss: 0.9068 - val_acc: 0.5812\n",
      "Epoch 8/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.8720 - acc: 0.6023 - val_loss: 0.8883 - val_acc: 0.5876\n",
      "Epoch 9/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.8503 - acc: 0.6208 - val_loss: 0.8654 - val_acc: 0.6096\n",
      "Epoch 10/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.8084 - acc: 0.6434 - val_loss: 0.8371 - val_acc: 0.6205\n",
      "Epoch 11/50\n",
      "25010/25010 [==============================] - 67s - loss: 0.7732 - acc: 0.6616 - val_loss: 0.8045 - val_acc: 0.6488\n",
      "Epoch 12/50\n",
      "25010/25010 [==============================] - 67s - loss: 0.7321 - acc: 0.6857 - val_loss: 0.7545 - val_acc: 0.6777\n",
      "Epoch 13/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.6897 - acc: 0.7087 - val_loss: 0.8197 - val_acc: 0.6366\n",
      "Epoch 14/50\n",
      "25010/25010 [==============================] - 67s - loss: 0.6386 - acc: 0.7367 - val_loss: 0.6786 - val_acc: 0.7193\n",
      "Epoch 15/50\n",
      "25010/25010 [==============================] - 67s - loss: 0.5855 - acc: 0.7630 - val_loss: 0.6389 - val_acc: 0.7426\n",
      "Epoch 16/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.5292 - acc: 0.7909 - val_loss: 0.5875 - val_acc: 0.7694\n",
      "Epoch 17/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.4799 - acc: 0.8132 - val_loss: 0.5474 - val_acc: 0.7887\n",
      "Epoch 18/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.4255 - acc: 0.8374 - val_loss: 0.4958 - val_acc: 0.8116\n",
      "Epoch 19/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.3914 - acc: 0.8515 - val_loss: 0.4950 - val_acc: 0.8095\n",
      "Epoch 20/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.3618 - acc: 0.8620 - val_loss: 0.4570 - val_acc: 0.8274\n",
      "Epoch 21/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.3190 - acc: 0.8812 - val_loss: 0.4213 - val_acc: 0.8428\n",
      "Epoch 22/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.2787 - acc: 0.8946 - val_loss: 0.3909 - val_acc: 0.8554\n",
      "Epoch 23/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.2488 - acc: 0.9075 - val_loss: 0.4288 - val_acc: 0.8410\n",
      "Epoch 24/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.2418 - acc: 0.9086 - val_loss: 0.3753 - val_acc: 0.8659\n",
      "Epoch 25/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.2058 - acc: 0.9239 - val_loss: 0.3377 - val_acc: 0.8769\n",
      "Epoch 26/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.1971 - acc: 0.9281 - val_loss: 0.3026 - val_acc: 0.8892\n",
      "Epoch 27/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.1606 - acc: 0.9414 - val_loss: 0.3135 - val_acc: 0.8860\n",
      "Epoch 28/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.1514 - acc: 0.9452 - val_loss: 0.2500 - val_acc: 0.9126\n",
      "Epoch 29/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.1187 - acc: 0.9586 - val_loss: 0.2630 - val_acc: 0.9070\n",
      "Epoch 30/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.1055 - acc: 0.9635 - val_loss: 0.2959 - val_acc: 0.9038\n",
      "Epoch 31/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.1132 - acc: 0.9611 - val_loss: 0.2317 - val_acc: 0.9201\n",
      "Epoch 32/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.0963 - acc: 0.9658 - val_loss: 0.2589 - val_acc: 0.9121\n",
      "Epoch 33/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.0791 - acc: 0.9731 - val_loss: 0.2276 - val_acc: 0.9234\n",
      "Epoch 34/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.0920 - acc: 0.9701 - val_loss: 0.1880 - val_acc: 0.9397\n",
      "Epoch 35/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.0495 - acc: 0.9850 - val_loss: 0.2164 - val_acc: 0.9290\n",
      "Epoch 36/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.1158 - acc: 0.9634 - val_loss: 0.2251 - val_acc: 0.9259\n",
      "Epoch 37/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.0387 - acc: 0.9902 - val_loss: 0.1429 - val_acc: 0.9563\n",
      "Epoch 38/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.0296 - acc: 0.9924 - val_loss: 0.2294 - val_acc: 0.9317\n",
      "Epoch 39/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.1169 - acc: 0.9647 - val_loss: 0.1945 - val_acc: 0.9399\n",
      "Epoch 40/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.0418 - acc: 0.9872 - val_loss: 0.1403 - val_acc: 0.9562\n",
      "Epoch 41/50\n",
      "25010/25010 [==============================] - 69s - loss: 0.0359 - acc: 0.9892 - val_loss: 0.1465 - val_acc: 0.9558\n",
      "Epoch 42/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.0658 - acc: 0.9786 - val_loss: 0.2583 - val_acc: 0.9223\n",
      "Epoch 43/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.0401 - acc: 0.9884 - val_loss: 0.1281 - val_acc: 0.9620\n",
      "Epoch 44/50\n",
      "25010/25010 [==============================] - 70s - loss: 0.0225 - acc: 0.9942 - val_loss: 0.1553 - val_acc: 0.9544\n",
      "Epoch 45/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.0802 - acc: 0.9749 - val_loss: 0.2437 - val_acc: 0.9212\n",
      "Epoch 46/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.0565 - acc: 0.9828 - val_loss: 0.1400 - val_acc: 0.9615\n",
      "Epoch 47/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.0164 - acc: 0.9963 - val_loss: 0.1114 - val_acc: 0.9693\n",
      "Epoch 48/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.0065 - acc: 0.9993 - val_loss: 0.0835 - val_acc: 0.9779\n",
      "Epoch 49/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.0042 - acc: 0.9995 - val_loss: 0.0860 - val_acc: 0.9771\n",
      "Epoch 50/50\n",
      "25010/25010 [==============================] - 68s - loss: 0.0042 - acc: 0.9995 - val_loss: 0.1587 - val_acc: 0.9577\n"
     ]
    }
   ],
   "source": [
    "n_input_node= 25\n",
    "n_nodes_hl1=500\n",
    "n_nodes_hl2=500\n",
    "n_nodes_hl3=500\n",
    "n_output_node = 10\n",
    "\n",
    "epochs =50\n",
    "batch_size = 100\n",
    "\n",
    "model = Sequential([\n",
    " Dense(output_dim=n_nodes_hl1, input_dim=n_input_node, activation='relu'),\n",
    " Dense(output_dim=n_nodes_hl3, input_dim=n_nodes_hl1, activation='relu'),\n",
    " Dense(output_dim=n_nodes_hl3, input_dim=n_nodes_hl2, activation='relu'),\n",
    "    \n",
    " Dense(output_dim=n_output_node, input_dim=n_nodes_hl3, activation='softmax'),\n",
    " ])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "trained_model_5d = model.fit(x_train, y_train, nb_epoch=epochs, batch_size=batch_size, \n",
    "                             validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    " i am getting max accuracy of test data at 48th epoch - 97.79%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
